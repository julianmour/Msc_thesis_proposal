%! Author = julianmour
%! Date = 01/05/2023


\section{Future Research Objectives}
In light of the preliminary work, we aim to further explore our ideas in the following directions:
\begin{itemize}
    \item Reduce the number of queries to the MILP verifier, and generally reduce the execution time:
    A main challenge in our current algorithm is the computation of the weakest points.
    This idea has been adapted from~\cite{MARVEL}, focusing on single label classifiers.
    In this setting, this computation involves at most $|C|$ queries per iteration to the MILP solver.
    In our setting, it involves  $|C|^2$ queries per iteration.
    This leads to a very high execution time.
    To reduce the number of queries, we plan to use incomplete verifiers (see~\ref{subsec:verifiers}) in some of these queries, in cases where they return an absolute answer.
    These verifiers tend to be a lot more efficient in time.
    We will also think of methods to reduce the total number of queries from $|C|^2$ to something more manageable.
%    \Dana{complete}.
    \item Increase the size of the robust neighborhoods: The size of the returned neighborhood depends on the optimizer and te CEGIS component.
    To increase the size, we aim to develop optimal cutting weights that minimally shrink a non-robust neighborhood to make it robust.
    We will also investigate ways to tell in which layers we can expand the neighborhood more at the expense of others, hoping it increases the total neighborhood size.
%    \Dana{complete}
     %This can be affected by many factors (e.g.\ the shrinking method used in the algorithm) - we will explore each of these factors and look for the best methods to achieve this goal.
\item Consider more complex datasets: In our preliminary research, we focus on the Double-MNIST dataset. In our research, we plan to consider more complex datasets, e.g., ones showing road images. 
    \item Infer explanations: Our algorithm finds a relation between two objects in a given image and a given multi-label classifier.
    We aim to generalize the relations to infer explanations on the robustness level of a multi-label classifier. The explanations can tell us how much and where we can perturb an image without affecting the classification of the target object. 
%    These can vary between different classifiers as well, which will also help us understand which type of multi-label networks are most vulnerable to perturbations in different locations in their inputs.
\end{itemize}
