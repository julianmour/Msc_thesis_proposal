\begin{thebibliography}{10}

\bibitem{SINGLElABEL1}
Naveed Akhtar and Ajmal Mian.
\newblock Threat of adversarial attacks on deep learning in computer vision: A
  survey.
\newblock {\em IEEE}, 2018.

\bibitem{PGD}
Ludwig Schmidt Dimitris Tsipras Adrian~Vladu Aleksander~Madry,
  Aleksandar~Makelov.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em ICLR}, 2018.

\bibitem{SINGLElABEL2}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock {\em IEEE}, 2017.

\bibitem{ABSTRACTINTER}
Markus Püschel Martin~Vechev Gagandeep~Singh, Timon~Gehr.
\newblock An abstract domain for certifying neural networks.
\newblock {\em ACM}, 2019.

\bibitem{INCOMPLETE2}
Matthew Mirman Markus Püschel Martin~Vechev Gagandeep~Singh, Timon~Gehr.
\newblock Fast and effective robustness certification.
\newblock {\em NeurIPS}, 2018.

\bibitem{ref7}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em In ICLR}, 2015.

\bibitem{MULTIlABEL1}
Qingquan Song; Haifeng Jin; Xiao Huang;~Xia Hu.
\newblock Multi-label adversarial perturbations.
\newblock {\em IEEE}, 2018.

\bibitem{SINGLElABEL3}
Jonathon~Shlens Ian J~Goodfellow and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em International Conference on Learning Representations}, 2015.

\bibitem{OracleGuided}
Gulwani S. Seshia S.A. Tiwari~A. Jha, S.
\newblock Oracle-guided component-based program synthesis.
\newblock {\em ICSE}, 2010.

\bibitem{DoubleMNIST}
Gulwani S. Seshia S.A. Tiwari A.Sara Sabour Nicholas Frosst Geoffrey E.~Hinton
  Jha, S.
\newblock Dynamic routing between capsules.
\newblock {\em NeurIPS}, 2017.

\bibitem{MultiVul2}
Neil~Gong Jinyuan~Jia, Wenjie~Qu.
\newblock Multiguard: Provably robust multi-label classification against
  adversarial examples.
\newblock {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{MARVEL}
Anan Kabaha and Dana~Drachsler Cohen.
\newblock Maximal robust neural network specifications via oracle-guided
  numerical optimization.
\newblock {\em VMCAI}, 2023.

\bibitem{CEGIS2}
Anan Kabaha and Dana Drachsler-Cohen.
\newblock Boosting robustness verification of semantic feature neighborhoods.
\newblock In Gagandeep Singh and Caterina Urban, editors, {\em Static
  Analysis}, pages 299--324, Cham, 2022. Springer Nature Switzerland.

\bibitem{COMPLETE}
Shiqi Wang Yihan Wang Suman Jana Xue Lin Cho-Jui~Hsieh Kaidi~Xu, Huan~Zhang.
\newblock Fast and complete: Enabling complete neural network verification with
  rapid and massively parallel incomplete verifiers, 11 2020.

\bibitem{ref15}
Alexey Kurakin, Ian~J. Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock {\em In ICLR}, 2017.

\bibitem{CEGIS1}
Changjiang Li, Shouling Ji, Haiqin Weng, Bo~Li, Jie Shi, Raheem Beyah, Shanqing
  Guo, Zonghui Wang, and Ting Wang.
\newblock Towards certifying the asymmetric robustness for neural networks:
  Quantification and applications.
\newblock {\em IEEE Transactions on Dependable and Secure Computing},
  19(6):3987--4001, 2022.

\bibitem{CEGIS3}
Chen Liu, Ryota Tomioka, and Volkan Cevher.
\newblock On certifying non-uniform bounds against adversarial attacks.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em
  Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of {\em Proceedings of Machine Learning Research}, pages
  4072--4081. PMLR, 09--15 Jun 2019.

\bibitem{ref56}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em In ICLR}, 2018.

\bibitem{IMAGETAGGING}
Kilian~Weinberger Minmin~Chen, Alice~Zheng.
\newblock Fast image tagging.
\newblock {\em Proceedings of the 30th International Conference on Machine
  Learning}, 2013.

\bibitem{ObjectDetection}
Poggio~T Papageorgiou, C.
\newblock A trainable system for object detection.
\newblock {\em International Journal of Computer Vision}, 2000.

\bibitem{MultiVul1}
Bernhard~Schölkopf Rohit~Babbar.
\newblock Adversarial extreme multi-label classification, 2018.

\bibitem{SINGLElABEL4}
Alhussein~Fawzi Seyed-Mohsen Moosavi-Dezfooli and Pascal Frossard.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 2016.

\bibitem{FacialRec}
Xiaojiang Peng Jianfei Yang Zhaoyang Zeng Yu~Qiao Sijie~Ji, Kai~Wang.
\newblock Multiple transfer learning and multi-label balanced training
  strategies for facial au detection in the wild.
\newblock {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) Workshops}, 2020.

\bibitem{VANILLAGRADIENT}
Andrea~Vedaldi Simonyan, Karen and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps., 2013.

\bibitem{MultiVul3}
Angelo Sotgiu Ambra Demontis Battista Biggio Marco~Gori Stefano~Melacci,
  Gabriele~Ciravegna.
\newblock Domain knowledge alleviates adversarial attacks in multi-label
  classifiers.
\newblock {\em IEEE}, 2022.

\bibitem{L0}
Bernt~Schiele Sukrut~Rao, David~Stutz.
\newblock Adversarial training against location-optimized adversarial patches.
\newblock {\em ECCV}, 2020.

\bibitem{szegedy2014intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks, 2014.

\bibitem{ref17}
Pedro Tabacof and Eduardo Valle.
\newblock Exploring the space of adversarial images.
\newblock {\em In IJCNN}, 2016.

\bibitem{INCOMPLETE1}
Timon Gehr; Matthew Mirman; Dana Drachsler-Cohen; Petar Tsankov; Swarat
  Chaudhuri;~Martin Vechev.
\newblock Safety and robustness certification of neural networks with abstract
  interpretation.
\newblock {\em IEEE}, 2018.

\bibitem{MIPVERIFY}
Russ~Tedrake Vincent~Tjeng, Kai~Xiao.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock {\em ICLR}, 2019.

\bibitem{MULTIlABEL3}
Zhuo Yang, Yufei Han, and Xiangliang Zhang.
\newblock Characterizing the evasion attackability of multi-label classifiers.
\newblock {\em Proceedings of the AAAI Conference on Artificial Intelligence},
  35(12):10647--10655, May 2021.

\bibitem{ref29}
Xiaoyong Yuan, Pan He, Qile Zhu, and Xiaolin Li.
\newblock Adversarial examples: Attacks and defenses for deep learning.
\newblock {\em In {IEEE} Trans. Neural Networks Learn. Syst}, 2019.

\bibitem{MULTIlABEL2}
Nan Zhou, Wenjian Luo, Xin Lin, Peilan Xu, and Zhenya Zhang.
\newblock Generating multi-label adversarial examples by linear programming.
\newblock In {\em 2020 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--8, 2020.

\end{thebibliography}
