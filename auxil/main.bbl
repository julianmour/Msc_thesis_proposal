\begin{thebibliography}{10}

\bibitem{PGD}
Ludwig Schmidt Dimitris Tsipras Adrian~Vladu Aleksander~Madry,
  Aleksandar~Makelov.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em ICLR}, 2018.

\bibitem{ref7}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em In ICLR}, 2015.

\bibitem{MARVEL}
Anan Kabaha and Dana~Drachsler Cohen.
\newblock Maximal robust neural network specifications via oracle-guided
  numerical optimization.
\newblock {\em VMCAI}, 2023.

\bibitem{ref15}
Alexey Kurakin, Ian~J. Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock {\em In ICLR}, 2017.

\bibitem{ref56}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em In ICLR}, 2018.

\bibitem{VANILLAGRADIENT}
Andrea~Vedaldi Simonyan, Karen and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps., 2013.

\bibitem{szegedy2014intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks, 2014.

\bibitem{ref17}
Pedro Tabacof and Eduardo Valle.
\newblock Exploring the space of adversarial images.
\newblock {\em In IJCNN}, 2016.

\bibitem{MIPVERIFY}
Russ~Tedrake Vincent~Tjeng, Kai~Xiao.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock {\em ICLR}, 2019.

\bibitem{ref29}
Xiaoyong Yuan, Pan He, Qile Zhu, and Xiaolin Li.
\newblock Adversarial examples: Attacks and defenses for deep learning.
\newblock {\em In {IEEE} Trans. Neural Networks Learn. Syst}, 2019.

\end{thebibliography}
