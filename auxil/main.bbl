\begin{thebibliography}{10}

\bibitem{SINGLElABEL1}
Naveed Akhtar and Ajmal Mian.
\newblock Threat of adversarial attacks on deep learning in computer vision: A
  survey.
\newblock {\em IEEE}, 2018.

\bibitem{PGD}
Ludwig Schmidt-Dimitris Tsipras Adrian~Vladu Aleksander~Madry,
  Aleksandar~Makelov.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em ICLR}, 2018.

\bibitem{SINGLElABEL2}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock {\em IEEE}, 2017.

\bibitem{ABSTRACTINTER}
Markus Püschel-Martin~Vechev Gagandeep~Singh, Timon~Gehr.
\newblock An abstract domain for certifying neural networks.
\newblock {\em ACM}, 2019.

\bibitem{INCOMPLETE2}
Matthew Mirman-Markus Püschel Martin~Vechev Gagandeep~Singh, Timon~Gehr.
\newblock Fast and effective robustness certification.
\newblock {\em NeurIPS}, 2018.

\bibitem{ref7}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em In ICLR}, 2015.

\bibitem{SINGLElABEL3}
Jonathon~Shlens Ian J~Goodfellow and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em International Conference on Learning Representations}, 2015.

\bibitem{OracleGuided}
Gulwani S. Seshia S.A.-Tiwari~A. Jha, S.
\newblock Oracle-guided component-based program synthesis.
\newblock {\em ICSE}, 2010.

\bibitem{DoubleMNIST}
Gulwani S. Seshia S.A.-Tiwari A.Sara Sabour Nicholas Frosst Geoffrey E.~Hinton
  Jha, S.
\newblock Dynamic routing between capsules.
\newblock {\em NeurIPS}, 2017.

\bibitem{MultiVul2}
Neil~Gong Jinyuan~Jia, Wenjie~Qu.
\newblock Multiguard: Provably robust multi-label classification against
  adversarial examples.
\newblock {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{MARVEL}
Anan Kabaha and Dana~Drachsler Cohen.
\newblock Maximal robust neural network specifications via oracle-guided
  numerical optimization.
\newblock {\em VMCAI}, 2023.

\bibitem{COMPLETE}
Shiqi Wang-Yihan Wang Suman Jana Xue Lin Cho-Jui~Hsieh Kaidi~Xu, Huan~Zhang.
\newblock Fast and complete: Enabling complete neural network verification with
  rapid and massively parallel incomplete verifiers, 11 2020.

\bibitem{ref15}
Alexey Kurakin, Ian~J. Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock {\em In ICLR}, 2017.

\bibitem{ref56}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em In ICLR}, 2018.

\bibitem{IMAGETAGGING}
Kilian~Weinberger Minmin~Chen, Alice~Zheng.
\newblock Fast image tagging.
\newblock {\em Proceedings of the 30th International Conference on Machine
  Learning}, 2013.

\bibitem{ObjectDetection}
Poggio~T Papageorgiou, C.
\newblock A trainable system for object detection.
\newblock {\em International Journal of Computer Vision}, 2000.

\bibitem{MultiVul1}
Bernhard~Schölkopf Rohit~Babbar.
\newblock Adversarial extreme multi-label classification, 2018.

\bibitem{SINGLElABEL4}
Alhussein~Fawzi Seyed-Mohsen Moosavi-Dezfooli and Pascal Frossard.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 2016.

\bibitem{MULTIlABEL}
Xin Wang-Siwei~Lyu Shu~Hu, Lipeng~Ke.
\newblock Tkml-ap: Adversarial attacks to top-k multi-label learning.
\newblock {\em ICCV}, 2021.

\bibitem{FacialRec}
Xiaojiang Peng-Jianfei Yang Zhaoyang Zeng Yu~Qiao Sijie~Ji, Kai~Wang.
\newblock Multiple transfer learning and multi-label balanced training
  strategies for facial au detection in the wild.
\newblock {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) Workshops}, 2020.

\bibitem{VANILLAGRADIENT}
Andrea~Vedaldi Simonyan, Karen and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps., 2013.

\bibitem{MultiVul3}
Angelo Sotgiu-Ambra Demontis Battista Biggio Marco~Gori Stefano~Melacci,
  Gabriele~Ciravegna.
\newblock Domain knowledge alleviates adversarial attacks in multi-label
  classifiers.
\newblock {\em IEEE}, 2022.

\bibitem{L0}
Bernt~Schiele Sukrut~Rao, David~Stutz.
\newblock Adversarial training against location-optimized adversarial patches.
\newblock {\em ECCV}, 2020.

\bibitem{szegedy2014intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks, 2014.

\bibitem{ref17}
Pedro Tabacof and Eduardo Valle.
\newblock Exploring the space of adversarial images.
\newblock {\em In IJCNN}, 2016.

\bibitem{INCOMPLETE1}
Timon Gehr; Matthew Mirman; Dana Drachsler-Cohen; Petar Tsankov; Swarat
  Chaudhuri;~Martin Vechev.
\newblock Safety and robustness certification of neural networks with abstract
  interpretation.
\newblock {\em IEEE}, 2018.

\bibitem{MIPVERIFY}
Russ~Tedrake Vincent~Tjeng, Kai~Xiao.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock {\em ICLR}, 2019.

\bibitem{ref29}
Xiaoyong Yuan, Pan He, Qile Zhu, and Xiaolin Li.
\newblock Adversarial examples: Attacks and defenses for deep learning.
\newblock {\em In {IEEE} Trans. Neural Networks Learn. Syst}, 2019.

\end{thebibliography}
